{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BlogFeedback Clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gd/lsdt5y754fl3r9jg4qztyy180000gn/T/ipykernel_43298/1712114100.py:18: DtypeWarning: Columns (284) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_df = pd.read_csv(\"merged_df_pruned_with_target.csv\", index_col = 0 )\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os \n",
    "\n",
    "train_df = pd.read_csv(\"merged_df_pruned_with_target.csv\", index_col = 0 )\n",
    "\n",
    "name_list = train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_51</th>\n",
       "      <th>sd_51</th>\n",
       "      <th>min_51</th>\n",
       "      <th>max_51</th>\n",
       "      <th>median_51</th>\n",
       "      <th>mean_52</th>\n",
       "      <th>sd_52</th>\n",
       "      <th>min_52</th>\n",
       "      <th>max_52</th>\n",
       "      <th>median_52</th>\n",
       "      <th>...</th>\n",
       "      <th>Sun_TP</th>\n",
       "      <th>num_parent</th>\n",
       "      <th>min_num_comments_P</th>\n",
       "      <th>max_num_comments_P</th>\n",
       "      <th>mean_num_comments_P</th>\n",
       "      <th>num_comments_next_24_TB</th>\n",
       "      <th>dow_P</th>\n",
       "      <th>high_engagement_v3</th>\n",
       "      <th>length_bucket</th>\n",
       "      <th>new_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.30467</td>\n",
       "      <td>53.845657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.52416</td>\n",
       "      <td>32.441880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Thu_P</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.30467</td>\n",
       "      <td>53.845657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.52416</td>\n",
       "      <td>32.441880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Wed_P</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.30467</td>\n",
       "      <td>53.845657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.52416</td>\n",
       "      <td>32.441880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Thu_P</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40.30467</td>\n",
       "      <td>53.845657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.52416</td>\n",
       "      <td>32.441880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Wed_P</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>40.30467</td>\n",
       "      <td>53.845657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.52416</td>\n",
       "      <td>32.441880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Thu_P</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52392</th>\n",
       "      <td>33.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>15.556349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mon_P</td>\n",
       "      <td>0</td>\n",
       "      <td>3k-4k</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52393</th>\n",
       "      <td>33.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>15.556349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mon_P</td>\n",
       "      <td>0</td>\n",
       "      <td>3k-4k</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52394</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Thu_P</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52395</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Thu_P</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52396</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Thu_P</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46439 rows × 285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean_51      sd_51  min_51  max_51  median_51   mean_52      sd_52  \\\n",
       "0      40.30467  53.845657     0.0   401.0       15.0  15.52416  32.441880   \n",
       "1      40.30467  53.845657     0.0   401.0       15.0  15.52416  32.441880   \n",
       "4      40.30467  53.845657     0.0   401.0       15.0  15.52416  32.441880   \n",
       "5      40.30467  53.845657     0.0   401.0       15.0  15.52416  32.441880   \n",
       "8      40.30467  53.845657     0.0   401.0       15.0  15.52416  32.441880   \n",
       "...         ...        ...     ...     ...        ...       ...        ...   \n",
       "52392  33.00000   0.000000    33.0    33.0       33.0  11.00000  15.556349   \n",
       "52393  33.00000   0.000000    33.0    33.0       33.0  11.00000  15.556349   \n",
       "52394   0.00000   0.000000     0.0     0.0        0.0   0.00000   0.000000   \n",
       "52395   0.00000   0.000000     0.0     0.0        0.0   0.00000   0.000000   \n",
       "52396   0.00000   0.000000     0.0     0.0        0.0   0.00000   0.000000   \n",
       "\n",
       "       min_52  max_52  median_52  ...  Sun_TP  num_parent  min_num_comments_P  \\\n",
       "0         0.0   377.0        3.0  ...     0.0         0.0                 0.0   \n",
       "1         0.0   377.0        3.0  ...     0.0         0.0                 0.0   \n",
       "4         0.0   377.0        3.0  ...     0.0         0.0                 0.0   \n",
       "5         0.0   377.0        3.0  ...     0.0         0.0                 0.0   \n",
       "8         0.0   377.0        3.0  ...     0.0         0.0                 0.0   \n",
       "...       ...     ...        ...  ...     ...         ...                 ...   \n",
       "52392     0.0    33.0        0.0  ...     0.0         0.0                 0.0   \n",
       "52393     0.0    33.0        0.0  ...     0.0         0.0                 0.0   \n",
       "52394     0.0     0.0        0.0  ...     0.0         0.0                 0.0   \n",
       "52395     0.0     0.0        0.0  ...     0.0         0.0                 0.0   \n",
       "52396     0.0     0.0        0.0  ...     0.0         0.0                 0.0   \n",
       "\n",
       "       max_num_comments_P  mean_num_comments_P  num_comments_next_24_TB  \\\n",
       "0                     0.0                  0.0                      1.0   \n",
       "1                     0.0                  0.0                      0.0   \n",
       "4                     0.0                  0.0                     27.0   \n",
       "5                     0.0                  0.0                      0.0   \n",
       "8                     0.0                  0.0                      9.0   \n",
       "...                   ...                  ...                      ...   \n",
       "52392                 0.0                  0.0                      0.0   \n",
       "52393                 0.0                  0.0                      0.0   \n",
       "52394                 0.0                  0.0                      0.0   \n",
       "52395                 0.0                  0.0                      0.0   \n",
       "52396                 0.0                  0.0                      0.0   \n",
       "\n",
       "       dow_P  high_engagement_v3  length_bucket  new_target  \n",
       "0      Thu_P                   0              0       False  \n",
       "1      Wed_P                   0              0       False  \n",
       "4      Thu_P                   0              0        True  \n",
       "5      Wed_P                   0              0       False  \n",
       "8      Thu_P                   0              0       False  \n",
       "...      ...                 ...            ...         ...  \n",
       "52392  Mon_P                   0          3k-4k       False  \n",
       "52393  Mon_P                   0          3k-4k       False  \n",
       "52394  Thu_P                   0              0       False  \n",
       "52395  Thu_P                   0              0       False  \n",
       "52396  Thu_P                   0              0       False  \n",
       "\n",
       "[46439 rows x 285 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['new_target'] = train_df.num_comments_next_24_TB >= 10\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove dependent cols (col 1...50)\n",
    "train_df_cleaned = train_df.iloc[:,50:]\n",
    "\n",
    "# Drop the dow_P as \n",
    "train_df_cleaned = train_df_cleaned.drop(columns = ['dow_P', 'length_bucket', 'min_num_comments_P', 'max_num_comments_P', 'mean_num_comments_P', 'high_engagement_v3', 'num_comments_next_24_TB'])\n",
    "\n",
    "Y = train_df_cleaned.new_target\n",
    "X = train_df_cleaned.drop(columns = ['new_target'])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "def resample_data(df_data, factor):\n",
    "    # Identify the larger and smaller class\n",
    "    is_larger_class = (df_data['new_target'] == False)\n",
    "    is_smaller_class = (df_data['new_target'] == True)\n",
    "\n",
    "    # Get the indices of each class\n",
    "    larger_class_indices = np.where(is_larger_class)[0]\n",
    "    smaller_class_indices = np.where(is_smaller_class)[0]\n",
    "\n",
    "    # Calculate the target number of samples for both classes\n",
    "    target_smaller_class_samples = len(smaller_class_indices) * factor\n",
    "\n",
    "    # Oversample the smaller class using bootstrapping\n",
    "    oversampled_smaller_class_indices = np.random.choice(\n",
    "        smaller_class_indices, size=target_smaller_class_samples, replace=True\n",
    "    )\n",
    "\n",
    "    # Calculate the number of additional rows added for the larger class\n",
    "    num_additional_rows =  len(oversampled_smaller_class_indices) - len(smaller_class_indices)\n",
    "\n",
    "    # Undersample the larger class\n",
    "    num_larger_class_samples = len(larger_class_indices)\n",
    "    undersampled_larger_class_indices = np.random.choice(\n",
    "        larger_class_indices, size=num_larger_class_samples - num_additional_rows, replace=False\n",
    "    )\n",
    "\n",
    "    # Combine the oversampled smaller class and undersampled larger class\n",
    "    combined_indices = np.concatenate([oversampled_smaller_class_indices, undersampled_larger_class_indices])\n",
    "\n",
    "    # Create the resampled DataFrame\n",
    "    df_data_resampled = df_data.iloc[combined_indices]\n",
    "\n",
    "    return df_data_resampled\n",
    "\n",
    "df_data = pd.concat([X_train, Y_train], axis = 1)\n",
    "df_data_sampled = resample_data(df_data, 6)\n",
    "Y_train2 = df_data_sampled.new_target\n",
    "X_train2 = df_data_sampled.drop(columns = ['new_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_target\n",
       "False    29703\n",
       "True      2804\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_target\n",
       "True     16824\n",
       "False    15683\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the folder you want to change to\n",
    "folder_name = \"bf_data\"  # Replace with the name of your target folder\n",
    "\n",
    "# Create the full path by joining the current directory and the folder name\n",
    "folder_path = os.path.join(\"/Users/lexy/Desktop/BlogFeedback\", folder_name)\n",
    "\n",
    "# Change the current working directory to the target folder\n",
    "os.chdir(folder_path)\n",
    "\n",
    "\n",
    "# Reading in Test Data\n",
    "def load_test_data(name_list_final):\n",
    "    test_filelist = []\n",
    "    for filename in os.listdir('.'):\n",
    "        if 'test' in filename:\n",
    "            #if((filename.split('.')[1] == '02') | (filename.split('.')[1] == '03')):\n",
    "            test_filelist.append(filename)\n",
    "    df_test = pd.DataFrame(columns = name_list_final)\n",
    "\n",
    "    for testfile in test_filelist:\n",
    "        df_temp = pd.read_csv(testfile, header = None, names = name_list_final)\n",
    "        df_test = pd.concat([df_test, df_temp], ignore_index = True)\n",
    "\n",
    "    stat_col_list = []\n",
    "    for i in range(51,61,1):\n",
    "        stat_col_list.append('mean' + '_' + str(i))\n",
    "        stat_col_list.append('sd' + '_' + str(i))\n",
    "        stat_col_list.append('min' + '_' + str(i))\n",
    "        stat_col_list.append('max' + '_' + str(i))\n",
    "        stat_col_list.append('median' + '_' + str(i))\n",
    "\n",
    "    df_test_stats = df_test[stat_col_list]\n",
    "    df_test['target'] = np.where((df_test.num_comments_next_24_TB) >= 10, 1, 0)\n",
    "\n",
    "    df_test.drop(stat_col_list, axis = 1, inplace = True)\n",
    "\n",
    "    return df_test\n",
    "\n",
    "name_list = train_df.columns\n",
    "name_list = name_list.drop(['dow_P', 'high_engagement_v3', 'length_bucket', 'min_num_comments_P', 'max_num_comments_P', 'mean_num_comments_P'])\n",
    "actual_test_data = load_test_data(name_list)\n",
    "\n",
    "Y_actual_test_data = actual_test_data.rename(columns = {'target':'new_target'}).new_target\n",
    "X_actual_test_data = actual_test_data.drop(['target', 'num_comments_next_24_TB'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of missing values:\", actual_test_data.isnull().values.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(\n",
    "                         learning_rate=0.01, # contribution of each tree\n",
    "                         n_estimators=500, # large values -> better performance\n",
    "                         random_state=127\n",
    "                     ) \n",
    "clf.fit(X_train2, Y_train2)\n",
    "test_proba = clf.predict_proba(X_test)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False   0.989454  0.850008  0.914446     12694\n",
      "        True   0.370994  0.907108  0.526612      1238\n",
      "\n",
      "    accuracy                       0.855082     13932\n",
      "   macro avg   0.680224  0.878558  0.720529     13932\n",
      "weighted avg   0.934498  0.855082  0.879983     13932\n",
      "\n",
      "TN: 10790\n",
      "FP: 1904\n",
      "FN: 115\n",
      "TP: 1123\n",
      "Recall: 0.907108239095315\n",
      "Precision: 0.3709943838784275\n",
      "AUC: 0.9467303953147953\n"
     ]
    }
   ],
   "source": [
    "print(cm:=classification_report(Y_test, y_pred, digits=6, target_names=None, output_dict=False))\n",
    "\n",
    "cm_v = confusion_matrix(Y_test, y_pred)\n",
    "tn,fp,fn,tp = cm_v.ravel()\n",
    "print(\"TN:\", tn)\n",
    "print(\"FP:\", fp)\n",
    "print(\"FN:\", fn)\n",
    "print(\"TP:\", tp)\n",
    "print(\"Recall:\", tp/(tp+fn))\n",
    "print(\"Precision:\", tp/(tp+fp))\n",
    "\n",
    "print(\"AUC:\", roc_auc_score(Y_test, test_proba[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(\n",
    "                         # loss='log_loss', # loss function to optimize ???\n",
    "                         learning_rate=0.1, # contribution of each tree\n",
    "                         n_estimators=100, # large values -> better performance\n",
    "                         subsample=1, #  values < 1.0 -> low variance and high bias\n",
    "                         criterion='friedman_mse', # measure the quality of a split\n",
    "                         max_depth=3, # tree depth limits the number of nodes\n",
    "                         random_state=127\n",
    "                     ) \n",
    "clf.fit(X_train2, Y_train2)\n",
    "test_proba = clf.predict_proba(X_test)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False   0.986090  0.871199  0.925091     12694\n",
      "        True   0.398233  0.873990  0.547155      1238\n",
      "\n",
      "    accuracy                       0.871447     13932\n",
      "   macro avg   0.692162  0.872595  0.736123     13932\n",
      "weighted avg   0.933853  0.871447  0.891508     13932\n",
      "\n",
      "TN: 11059\n",
      "FP: 1635\n",
      "FN: 156\n",
      "TP: 1082\n",
      "Recall: 0.8739903069466882\n",
      "Precision: 0.39823334560176665\n",
      "AUC: 0.9427456473273089\n"
     ]
    }
   ],
   "source": [
    "print(cm:=classification_report(Y_test, y_pred, digits=6, target_names=None, output_dict=False))\n",
    "\n",
    "cm_v = confusion_matrix(Y_test, y_pred)\n",
    "tn,fp,fn,tp = cm_v.ravel()\n",
    "print(\"TN:\", tn)\n",
    "print(\"FP:\", fp)\n",
    "print(\"FN:\", fn)\n",
    "print(\"TP:\", tp)\n",
    "print(\"Recall:\", tp/(tp+fn))\n",
    "print(\"Precision:\", tp/(tp+fp))\n",
    "\n",
    "print(\"AUC:\", roc_auc_score(Y_test, test_proba[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False   0.982148  0.836458  0.903467     12694\n",
      "        True   0.334829  0.844103  0.479468      1238\n",
      "\n",
      "    accuracy                       0.837138     13932\n",
      "   macro avg   0.658488  0.840281  0.691468     13932\n",
      "weighted avg   0.924627  0.837138  0.865791     13932\n",
      "\n",
      "TN: 10618\n",
      "FP: 2076\n",
      "FN: 193\n",
      "TP: 1045\n",
      "Recall: 0.8441033925686591\n",
      "Precision: 0.3348285805831464\n",
      "AUC: 0.9066006404511513\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(\n",
    "                         n_estimators=100, \n",
    "                         criterion='gini', \n",
    "                         max_depth=3, \n",
    "                         n_jobs=-1, \n",
    "                         max_samples=0.3, \n",
    "                         random_state=127\n",
    "                     )\n",
    "\n",
    "clf.fit(X_train2, Y_train2)\n",
    "test_proba = clf.predict_proba(X_test)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(cm:=classification_report(Y_test, y_pred, digits=6, target_names=None, output_dict=False))\n",
    "\n",
    "cm_v = confusion_matrix(Y_test, y_pred)\n",
    "tn,fp,fn,tp = cm_v.ravel()\n",
    "print(\"TN:\", tn)\n",
    "print(\"FP:\", fp)\n",
    "print(\"FN:\", fn)\n",
    "print(\"TP:\", tp)\n",
    "print(\"Recall:\", tp/(tp+fn))\n",
    "print(\"Precision:\", tp/(tp+fp))\n",
    "\n",
    "print(\"AUC:\", roc_auc_score(Y_test, test_proba[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Final Model (Hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/lexy/Desktop/BlogFeedback/BF_Clf.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lexy/Desktop/BlogFeedback/BF_Clf.ipynb#Y110sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m best_params, best_auc_score\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lexy/Desktop/BlogFeedback/BF_Clf.ipynb#Y110sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# Example usage:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lexy/Desktop/BlogFeedback/BF_Clf.ipynb#Y110sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# Replace 'X' and 'y' with your feature matrix and target variable\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lexy/Desktop/BlogFeedback/BF_Clf.ipynb#Y110sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m best_params, best_auc_score \u001b[39m=\u001b[39m tune_gradient_boosting_hyperparameters(X_train2, Y_train2)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lexy/Desktop/BlogFeedback/BF_Clf.ipynb#Y110sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest Hyperparameters:\u001b[39m\u001b[39m\"\u001b[39m, best_params)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lexy/Desktop/BlogFeedback/BF_Clf.ipynb#Y110sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest AUC Score:\u001b[39m\u001b[39m\"\u001b[39m, best_auc_score)\n",
      "\u001b[1;32m/Users/lexy/Desktop/BlogFeedback/BF_Clf.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lexy/Desktop/BlogFeedback/BF_Clf.ipynb#Y110sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mclf, param_grid\u001b[39m=\u001b[39mparam_grid, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, scoring\u001b[39m=\u001b[39mauc_scorer, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lexy/Desktop/BlogFeedback/BF_Clf.ipynb#Y110sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Fit the model to find the best hyperparameters\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lexy/Desktop/BlogFeedback/BF_Clf.ipynb#Y110sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m grid_search\u001b[39m.\u001b[39mfit(X, y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lexy/Desktop/BlogFeedback/BF_Clf.ipynb#Y110sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# Get the best hyperparameters and their corresponding AUC score\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lexy/Desktop/BlogFeedback/BF_Clf.ipynb#Y110sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m best_params \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_params_\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[39m=\u001b[39mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[39m=\u001b[39mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[39mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[39menumerate\u001b[39m(candidate_params), \u001b[39menumerate\u001b[39m(cv\u001b[39m.\u001b[39msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget(timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39mresult(timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    454\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "\n",
    "def tune_gradient_boosting_hyperparameters(X, y):\n",
    "    # Define the hyperparameter grid to search\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'min_samples_split': [2, 3, 4],\n",
    "        'min_samples_leaf': [1, 2, 3],\n",
    "    }\n",
    "\n",
    "    # Create a Gradient Boosting classifier\n",
    "    clf = GradientBoostingClassifier()\n",
    "\n",
    "    # Define AUC as the scoring metric\n",
    "    auc_scorer = make_scorer(roc_auc_score)\n",
    "\n",
    "    # Initialize GridSearchCV with cross-validation and AUC scoring\n",
    "    grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, scoring=auc_scorer, n_jobs=-1)\n",
    "\n",
    "    # Fit the model to find the best hyperparameters\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # Get the best hyperparameters and their corresponding AUC score\n",
    "    best_params = grid_search.best_params_\n",
    "    best_auc_score = grid_search.best_score_\n",
    "\n",
    "    return best_params, best_auc_score\n",
    "\n",
    "# Example usage:\n",
    "# Replace 'X' and 'y' with your feature matrix and target variable\n",
    "best_params, best_auc_score = tune_gradient_boosting_hyperparameters(X_train2, Y_train2)\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best AUC Score:\", best_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.986486  0.701923  0.820225       104\n",
      "           1   0.243902  0.909091  0.384615        11\n",
      "\n",
      "    accuracy                       0.721739       115\n",
      "   macro avg   0.615194  0.805507  0.602420       115\n",
      "weighted avg   0.915457  0.721739  0.778558       115\n",
      "\n",
      "TN: 73\n",
      "FP: 31\n",
      "FN: 1\n",
      "TP: 10\n",
      "Recall: 0.9090909090909091\n",
      "Precision: 0.24390243902439024\n",
      "AUC: 0.8011363636363635\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(\n",
    "                         learning_rate=0.01, # contribution of each tree\n",
    "                         n_estimators=500, # large values -> better performance\n",
    "                         random_state=127\n",
    "                     ) \n",
    "clf.fit(X_train2, Y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.981636  0.749151  0.849779      7064\n",
      "           1   0.206449  0.823214  0.330111       560\n",
      "\n",
      "    accuracy                       0.754591      7624\n",
      "   macro avg   0.594042  0.786182  0.589945      7624\n",
      "weighted avg   0.924697  0.754591  0.811608      7624\n",
      "\n",
      "TN: 5292\n",
      "FP: 1772\n",
      "FN: 99\n",
      "TP: 461\n",
      "Recall: 0.8232142857142857\n",
      "Precision: 0.206448723690103\n",
      "AUC: 0.860502826201262\n"
     ]
    }
   ],
   "source": [
    "test_proba = clf.predict_proba(X_actual_test_data)\n",
    "y_pred = clf.predict(X_actual_test_data)\n",
    "\n",
    "print(cm:=classification_report(Y_actual_test_data, y_pred, digits=6, target_names=None, output_dict=False))\n",
    "\n",
    "cm_v = confusion_matrix(Y_actual_test_data, y_pred)\n",
    "tn,fp,fn,tp = cm_v.ravel()\n",
    "print(\"TN:\", tn)\n",
    "print(\"FP:\", fp)\n",
    "print(\"FN:\", fn)\n",
    "print(\"TP:\", tp)\n",
    "print(\"Recall:\", tp/(tp+fn))\n",
    "print(\"Precision:\", tp/(tp+fp))\n",
    "\n",
    "print(\"AUC:\", roc_auc_score(Y_actual_test_data, test_proba[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(random_state=127, subsample=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=127, subsample=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(random_state=127, subsample=1)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(\n",
    "                         # loss='log_loss', # loss function to optimize ???\n",
    "                         learning_rate=0.1, # contribution of each tree\n",
    "                         n_estimators=100, # large values -> better performance\n",
    "                         subsample=1, #  values < 1.0 -> low variance and high bias\n",
    "                         criterion='friedman_mse', # measure the quality of a split\n",
    "                         max_depth=3, # tree depth limits the number of nodes\n",
    "                         random_state=127\n",
    "                     ) \n",
    "clf.fit(X_train2, Y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.969625  0.804360  0.879294      7064\n",
      "           1   0.216553  0.682143  0.328744       560\n",
      "\n",
      "    accuracy                       0.795383      7624\n",
      "   macro avg   0.593089  0.743251  0.604019      7624\n",
      "weighted avg   0.914310  0.795383  0.838855      7624\n",
      "\n",
      "TN: 5682\n",
      "FP: 1382\n",
      "FN: 178\n",
      "TP: 382\n",
      "Recall: 0.6821428571428572\n",
      "Precision: 0.2165532879818594\n",
      "AUC: 0.787429471363857\n"
     ]
    }
   ],
   "source": [
    "test_proba = clf.predict_proba(X_actual_test_data)\n",
    "y_pred = clf.predict(X_actual_test_data)\n",
    "\n",
    "print(cm:=classification_report(Y_actual_test_data, y_pred, digits=6, target_names=None, output_dict=False))\n",
    "\n",
    "cm_v = confusion_matrix(Y_actual_test_data, y_pred)\n",
    "tn,fp,fn,tp = cm_v.ravel()\n",
    "print(\"TN:\", tn)\n",
    "print(\"FP:\", fp)\n",
    "print(\"FN:\", fn)\n",
    "print(\"TP:\", tp)\n",
    "print(\"Recall:\", tp/(tp+fn))\n",
    "print(\"Precision:\", tp/(tp+fp))\n",
    "\n",
    "print(\"AUC:\", roc_auc_score(Y_actual_test_data, test_proba[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.951887  0.960646  0.956246      7064\n",
      "           1   0.438384  0.387500  0.411374       560\n",
      "\n",
      "    accuracy                       0.918547      7624\n",
      "   macro avg   0.695135  0.674073  0.683810      7624\n",
      "weighted avg   0.914169  0.918547  0.916224      7624\n",
      "\n",
      "TN: 6786\n",
      "FP: 278\n",
      "FN: 343\n",
      "TP: 217\n",
      "Recall: 0.3875\n",
      "Precision: 0.4383838383838384\n",
      "AUC: 0.8653034500889825\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(\n",
    "                         n_estimators=100, \n",
    "                         criterion='gini', \n",
    "                         max_depth=3, \n",
    "                         n_jobs=-1, \n",
    "                         max_samples=0.3, \n",
    "                         random_state=127\n",
    "                     )\n",
    "\n",
    "clf.fit(X_train2, Y_train2)\n",
    "\n",
    "test_proba = clf.predict_proba(X_actual_test_data)\n",
    "y_pred = clf.predict(X_actual_test_data)\n",
    "\n",
    "print(cm:=classification_report(Y_actual_test_data, y_pred, digits=6, target_names=None, output_dict=False))\n",
    "\n",
    "cm_v = confusion_matrix(Y_actual_test_data, y_pred)\n",
    "tn,fp,fn,tp = cm_v.ravel()\n",
    "print(\"TN:\", tn)\n",
    "print(\"FP:\", fp)\n",
    "print(\"FN:\", fn)\n",
    "print(\"TP:\", tp)\n",
    "print(\"Recall:\", tp/(tp+fn))\n",
    "print(\"Precision:\", tp/(tp+fp))\n",
    "\n",
    "print(\"AUC:\", roc_auc_score(Y_actual_test_data, test_proba[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
